{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfOqDO03a7ONJ8JYD7ktZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/random_thoughts/blob/main/ML_interivew_FeatureEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yS1OjsBIoAP2"
      },
      "outputs": [],
      "source": [
        "# 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 Feature hashing"
      ],
      "metadata": {
        "id": "h2z37CPWEN6X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example data\n",
        "data = [\n",
        "    {'feature1': 'cat', 'feature2': 'red'},\n",
        "    {'feature1': 'dog', 'feature2': 'blue'},\n",
        "    {'feature1': 'bird', 'feature2': 'green'},\n",
        "]\n",
        "\n",
        "# Define the hash function\n",
        "def feature_hashing(text, num_buckets):\n",
        "    return hash(text) % num_buckets\n",
        "\n",
        "# Get unique feature values\n",
        "feature1_values = set(sample['feature1'] for sample in data)\n",
        "feature2_values = set(sample['feature2'] for sample in data)\n",
        "\n",
        "# Define the number of hash buckets\n",
        "num_buckets = 5\n",
        "\n",
        "# Create a mapping of feature values to hash buckets\n",
        "feature1_hash_map = {value: feature_hashing(value, num_buckets) for value in feature1_values}\n",
        "feature2_hash_map = {value: feature_hashing(value, num_buckets) for value in feature2_values}\n",
        "\n",
        "# Convert the data into hashed features\n",
        "hashed_data = [\n",
        "    {'feature1': feature1_hash_map[sample['feature1']], 'feature2': feature2_hash_map[sample['feature2']]}\n",
        "    for sample in data\n",
        "]\n",
        "\n",
        "# Convert the data into PyTorch tensors\n",
        "feature1_tensor = torch.tensor([sample['feature1'] for sample in hashed_data], dtype=torch.long)\n",
        "feature2_tensor = torch.tensor([sample['feature2'] for sample in hashed_data], dtype=torch.long)\n",
        "\n",
        "# Create a tensor of indices for the EmbeddingBag layer\n",
        "indices = torch.tensor([0, 1, 2])  # Assuming three samples in the data\n",
        "\n",
        "# Concatenate the tensors along the second dimension\n",
        "input_tensor = torch.cat([feature1_tensor.unsqueeze(1), feature2_tensor.unsqueeze(1)], dim=1)\n",
        "\n",
        "# Define the embedding layer\n",
        "embedding_layer = nn.EmbeddingBag(num_buckets, embedding_dim=5, sparse=True)\n",
        "\n",
        "# # Forward pass\n",
        "# output = embedding_layer(input_tensor, indices)\n",
        "\n",
        "# Print the result\n",
        "print(\"Input Tensor:\")\n",
        "print(input_tensor)\n",
        "# print(\"\\nOutput Tensor:\")\n",
        "# print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZIW9peoERTL",
        "outputId": "8923b08c-9ee7-41e0-ed7c-dc050c36815d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor:\n",
            "tensor([[4, 1],\n",
            "        [4, 1],\n",
            "        [1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8PLjyoINEfdF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized Cross Entropy"
      ],
      "metadata": {
        "id": "qfkqloqfIZF_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def normalized_cross_entropy_loss(log_probs, targets, reduction='mean'):\n",
        "    \"\"\"\n",
        "    Compute Normalized Cross Entropy Loss.\n",
        "\n",
        "    Args:\n",
        "        log_probs (torch.Tensor): Log probabilities from the model.\n",
        "        targets (torch.Tensor): True labels.\n",
        "        reduction (str, optional): Specifies the reduction to apply to the loss.\n",
        "            Options are 'none', 'mean', or 'sum'. Default is 'mean'.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Normalized Cross Entropy Loss.\n",
        "    \"\"\"\n",
        "    num_classes = log_probs.size(-1)\n",
        "    loss = F.nll_loss(log_probs, targets, reduction=reduction, ignore_index=num_classes - 1)\n",
        "    return loss / torch.log(torch.tensor(num_classes, dtype=loss.dtype))\n",
        "\n",
        "# Example usage\n",
        "log_probs = torch.rand((32, 10), requires_grad=True)\n",
        "targets = torch.randint(0, 10, (32,), dtype=torch.long)\n",
        "\n",
        "nce_loss = normalized_cross_entropy_loss(F.log_softmax(log_probs, dim=-1), targets)\n",
        "print(\"Normalized Cross Entropy Loss:\", nce_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW4vtuMrQ6rB",
        "outputId": "0e244ab5-0dbb-41bd-82a2-6d4ad1faf5be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Cross Entropy Loss: 0.986573338508606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#application\n",
        "log_probs = torch.tensor([1.0] * 10)\n",
        "targets = torch.tensor([0.1] * 10,dtype=torch.long)\n",
        "\n",
        "normalized_cross_entropy_loss(log_probs, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D59iKsVS5ayo",
        "outputId": "fa08f238-7cac-44ff-d32a-0c24455d9cb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.4343)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Q2noZbIQ9Hv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iri0hKhB6PLH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}