{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmKmuWEhvmzyg7RgRjwQmm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Papa-Panda/random_thoughts/blob/main/Tranformer_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "B8H3vglvxFYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "IxU7S5hO1zcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Transformer model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_encoding = PositionalEncoding(embedding_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.decoder = nn.Linear(embedding_dim, vocab_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoding(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.encoder(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jXRchfc8wynH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input and output sequences\n",
        "input_seq = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "output_seq = torch.tensor([[4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "# output_seq = torch.tensor([[12, 15, 18], [21, 24, 27], [30, 33, 36]])"
      ],
      "metadata": {
        "id": "a0A4vaJPxBlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and optimizer\n",
        "model = Transformer(vocab_size=13, embedding_dim=16, hidden_dim=32, num_layers=2, num_heads=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_seq)\n",
        "    loss = F.cross_entropy(output.view(-1, 13), output_seq.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdgE3FMz2AIy",
        "outputId": "f7f62879-3c3e-41e3-9297-a56defd3d6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 2.9981\n",
            "Epoch 100, loss: 0.7456\n",
            "Epoch 200, loss: 0.3032\n",
            "Epoch 300, loss: 0.1172\n",
            "Epoch 400, loss: 0.0720\n",
            "Epoch 500, loss: 0.0581\n",
            "Epoch 600, loss: 0.0250\n",
            "Epoch 700, loss: 0.0193\n",
            "Epoch 800, loss: 0.0146\n",
            "Epoch 900, loss: 0.0103\n",
            "Epoch 1000, loss: 0.0086\n",
            "Epoch 1100, loss: 0.0134\n",
            "Epoch 1200, loss: 0.0083\n",
            "Epoch 1300, loss: 0.0056\n",
            "Epoch 1400, loss: 0.0050\n",
            "Epoch 1500, loss: 0.0039\n",
            "Epoch 1600, loss: 0.0032\n",
            "Epoch 1700, loss: 0.0041\n",
            "Epoch 1800, loss: 0.0027\n",
            "Epoch 1900, loss: 0.0038\n",
            "Epoch 2000, loss: 0.0030\n",
            "Epoch 2100, loss: 0.0023\n",
            "Epoch 2200, loss: 0.0016\n",
            "Epoch 2300, loss: 0.0012\n",
            "Epoch 2400, loss: 0.0013\n",
            "Epoch 2500, loss: 0.0010\n",
            "Epoch 2600, loss: 0.0011\n",
            "Epoch 2700, loss: 0.0017\n",
            "Epoch 2800, loss: 0.0009\n",
            "Epoch 2900, loss: 0.0009\n",
            "Epoch 3000, loss: 0.0008\n",
            "Epoch 3100, loss: 0.0009\n",
            "Epoch 3200, loss: 0.0007\n",
            "Epoch 3300, loss: 0.0006\n",
            "Epoch 3400, loss: 0.0010\n",
            "Epoch 3500, loss: 0.0005\n",
            "Epoch 3600, loss: 0.0005\n",
            "Epoch 3700, loss: 0.0005\n",
            "Epoch 3800, loss: 0.0016\n",
            "Epoch 3900, loss: 0.0004\n",
            "Epoch 4000, loss: 0.0003\n",
            "Epoch 4100, loss: 0.0004\n",
            "Epoch 4200, loss: 0.0003\n",
            "Epoch 4300, loss: 0.2040\n",
            "Epoch 4400, loss: 0.0004\n",
            "Epoch 4500, loss: 0.0003\n",
            "Epoch 4600, loss: 0.0004\n",
            "Epoch 4700, loss: 0.0004\n",
            "Epoch 4800, loss: 0.0002\n",
            "Epoch 4900, loss: 0.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_input = torch.tensor([[6, 9, 8]])\n",
        "    test_output = model(test_input).argmax(-1)\n",
        "    print(f\"Input: {test_input.tolist()}, Output: {test_output.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iFHcZQL2Bxf",
        "outputId": "ba62929c-5dd5-4d32-93b8-e40edf8dff1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [[6, 9, 8]], Output: [[9, 12, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VVILH2v3Idu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uagwNUF53gJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}